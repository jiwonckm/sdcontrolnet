{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8uoeJ82qt8i"
      },
      "outputs": [],
      "source": [
        "# https://github.com/sniklaus/pytorch-hed/blob/master/run.py HED boundary processing in pytorch\n",
        "\n",
        "import getopt\n",
        "import numpy\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import sys\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buWAJHG2ukhH",
        "outputId": "4a5869ce-5247-481d-c641-0c50a3da708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "use_gdrive = True\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpZ3_qcdhR_S"
      },
      "outputs": [],
      "source": [
        "torch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n",
        "\n",
        "torch.backends.cudnn.enabled = False # make sure to use cudnn for computational performance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3lcERheiC3b"
      },
      "outputs": [],
      "source": [
        "arguments_strModel = 'bsds500' # only 'bsds500' for now\n",
        "arguments_strIn = './images/sample.png'\n",
        "arguments_strOut = \"/content/drive/MyDrive/CVproject/Data/processedData/000001.jpg\"\n",
        "data_dir = \"/content/drive/MyDrive/CVproject/Data/processedData/\"\n",
        "arguments_strIn = \"/content/drive/MyDrive/CVproject/Data/data/000001.jpg\"\n",
        "#set variables here\n",
        "# for strOption, strArgument in getopt.getopt(sys.argv[1:], '', [ strParameter[2:] + '=' for strParameter in sys.argv[1::2] ])[0]:\n",
        "#     if strOption == '--model' and strArgument != '': arguments_strModel = strArgument # which model to use\n",
        "#     if strOption == '--in' and strArgument != '': arguments_strIn = strArgument # path to the input image\n",
        "#     if strOption == '--out' and strArgument != '': arguments_strOut = strArgument # path to where the output should be stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd-R3MRTiC_a"
      },
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.netVggOne = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.netVggTwo = torch.nn.Sequential(\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.netVggThr = torch.nn.Sequential(\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.netVggFou = torch.nn.Sequential(\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.netVggFiv = torch.nn.Sequential(\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.netScoreOne = torch.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.netScoreTwo = torch.nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.netScoreThr = torch.nn.Conv2d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.netScoreFou = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.netScoreFiv = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.netCombine = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=5, out_channels=1, kernel_size=1, stride=1, padding=0),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.load_state_dict({ strKey.replace('module', 'net'): tenWeight for strKey, tenWeight in torch.hub.load_state_dict_from_url(url='http://content.sniklaus.com/github/pytorch-hed/network-' + arguments_strModel + '.pytorch', file_name='hed-' + arguments_strModel).items() })\n",
        "    # end\n",
        "\n",
        "    def forward(self, tenInput):\n",
        "        tenInput = tenInput * 255.0\n",
        "        tenInput = tenInput - torch.tensor(data=[104.00698793, 116.66876762, 122.67891434], dtype=tenInput.dtype, device=tenInput.device).view(1, 3, 1, 1)\n",
        "\n",
        "        tenVggOne = self.netVggOne(tenInput)\n",
        "        tenVggTwo = self.netVggTwo(tenVggOne)\n",
        "        tenVggThr = self.netVggThr(tenVggTwo)\n",
        "        tenVggFou = self.netVggFou(tenVggThr)\n",
        "        tenVggFiv = self.netVggFiv(tenVggFou)\n",
        "\n",
        "        tenScoreOne = self.netScoreOne(tenVggOne)\n",
        "        tenScoreTwo = self.netScoreTwo(tenVggTwo)\n",
        "        tenScoreThr = self.netScoreThr(tenVggThr)\n",
        "        tenScoreFou = self.netScoreFou(tenVggFou)\n",
        "        tenScoreFiv = self.netScoreFiv(tenVggFiv)\n",
        "\n",
        "        tenScoreOne = torch.nn.functional.interpolate(input=tenScoreOne, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n",
        "        tenScoreTwo = torch.nn.functional.interpolate(input=tenScoreTwo, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n",
        "        tenScoreThr = torch.nn.functional.interpolate(input=tenScoreThr, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n",
        "        tenScoreFou = torch.nn.functional.interpolate(input=tenScoreFou, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n",
        "        tenScoreFiv = torch.nn.functional.interpolate(input=tenScoreFiv, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n",
        "\n",
        "        return self.netCombine(torch.cat([ tenScoreOne, tenScoreTwo, tenScoreThr, tenScoreFou, tenScoreFiv ], 1))\n",
        "    # end\n",
        "# end\n",
        "\n",
        "netNetwork = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEtPt1PViP2E"
      },
      "outputs": [],
      "source": [
        "def estimate(tenInput):\n",
        "    global netNetwork\n",
        "\n",
        "    if netNetwork is None:\n",
        "        # netNetwork = Network().cuda().eval()\n",
        "        netNetwork = Network().eval()\n",
        "    # end\n",
        "\n",
        "    intWidth = tenInput.shape[2]\n",
        "    intHeight = tenInput.shape[1]\n",
        "\n",
        "    # assert(intWidth == 480) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n",
        "    # assert(intHeight == 320) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n",
        "\n",
        "    # return netNetwork(tenInput.cuda().view(1, 3, intHeight, intWidth))[0, :, :, :].cpu()\n",
        "    return netNetwork(tenInput.view(1, 3, intHeight, intWidth))[0, :, :, :].cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxpc3RpiRTU"
      },
      "outputs": [],
      "source": [
        "l = ['{0:06}'.format(num) for num in range(0, 10000)]\n",
        "for i in l:\n",
        "    arguments_strIn = arguments_strIn[:-10] + i + \".jpg\"\n",
        "    arguments_strOut = arguments_strOut[:-10] + i + \".jpg\"\n",
        "    tenInput = torch.FloatTensor(numpy.ascontiguousarray(numpy.array(PIL.Image.open(arguments_strIn))[:, :, ::-1].transpose(2, 0, 1).astype(numpy.float32) * (1.0 / 255.0)))\n",
        "\n",
        "    tenOutput = estimate(tenInput)\n",
        "\n",
        "    PIL.Image.fromarray((tenOutput.clip(0.0, 1.0).numpy().transpose(1, 2, 0)[:, :, 0] * 255.0).astype(numpy.uint8)).save(arguments_strOut)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}