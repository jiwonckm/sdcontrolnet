{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Load the dataset**"
      ],
      "metadata": {
        "id": "AWZ2aNMfkOXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!git clone https://github.com/BVLC/caffe.git\n",
        "!git reset --hard 9b891540183ddc834a02b2bd81b31afae71b2153 #reset to the newest revision that worked OK on 27.03.2021\n",
        "# !sudo apt-cache search libhdf5-\n",
        "# !sudo apt-cache search gflags\n",
        "# !sudo apt --fix-broken install\n",
        "!sudo apt-get install libgflags2.2 \n",
        "!sudo apt-get install libgflags-dev\n",
        "!sudo apt-get install libgoogle-glog-dev\n",
        "# !sudo apt-get install libhdf5-10 - replaced with 100\n",
        "!sudo apt-get install libhdf5-100\n",
        "!sudo apt-get install libhdf5-serial-dev\n",
        "!sudo apt-get install libhdf5-dev\n",
        "# !sudo apt-get install libhdf5-cpp-11 - replaced with 100\n",
        "!sudo apt-get install libhdf5-cpp-100\n",
        "!sudo apt-get install libprotobuf-dev protobuf-compiler\n",
        "!find /usr -iname \"*hdf5.so\"\n",
        "# got: /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "!find /usr -iname \"*hdf5_hl.so\"\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial.so /usr/lib/x86_64-linux-gnu/libhdf5.so\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so /usr/lib/x86_64-linux-gnu/libhdf5_hl.so\n",
        "%env CPATH=\"/usr/include/hdf5/serial/\"\n",
        "!sudo apt-get install libleveldb-dev\n",
        "!sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "!sudo apt-get install libsnappy-dev\n",
        "!echo $CPATH\n",
        "%cd caffe\n",
        "!ls\n",
        "!make clean\n",
        "!cp Makefile.config.example Makefile.config\n",
        "!sed -i 's/-gencode arch=compute_20/#-gencode arch=compute_20/' Makefile.config #old cuda versions won't compile \n",
        "!sed -i 's/\\/usr\\/local\\/include/\\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//'  Makefile.config #one of the 4 things needed to fix hdf5 issues\n",
        "!sed -i 's/# OPENCV_VERSION := 3/OPENCV_VERSION := 3/' Makefile.config #We actually use opencv 4.1.2, but it's similar enough to opencv 3.\n",
        "!sed -i 's/code=compute_61/code=compute_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75/' Makefile.config #support for new GPUs\n",
        "!make all -j 4 # -j would use all availiable cores, but RAM related errors occur\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr9-ZPsf2eiS",
        "outputId": "23b84397-8670-42e6-ac9e-1f5bab73c2b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "Cloning into 'caffe'...\n",
            "remote: Enumerating objects: 65274, done.\u001b[K\n",
            "remote: Total 65274 (delta 0), reused 0 (delta 0), pack-reused 65274\u001b[K\n",
            "Receiving objects: 100% (65274/65274), 74.14 MiB | 17.78 MiB/s, done.\n",
            "Resolving deltas: 100% (41242/41242), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgflags2.2 is already the newest version (2.2.2-1build1).\n",
            "libgflags2.2 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgflags-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 96.6 kB of archives.\n",
            "After this operation, 674 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgflags-dev amd64 2.2.2-1build1 [96.6 kB]\n",
            "Fetched 96.6 kB in 1s (170 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libgflags-dev.\n",
            "(Reading database ... 131926 files and directories currently installed.)\n",
            "Preparing to unpack .../libgflags-dev_2.2.2-1build1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.2-1build1) ...\n",
            "Setting up libgflags-dev (2.2.2-1build1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libgoogle-glog-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 76.4 kB of archives.\n",
            "After this operation, 374 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgoogle-glog-dev amd64 0.4.0-1build1 [76.4 kB]\n",
            "Fetched 76.4 kB in 0s (172 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "(Reading database ... 131946 files and directories currently installed.)\n",
            "Preparing to unpack .../libgoogle-glog-dev_0.4.0-1build1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.4.0-1build1) ...\n",
            "Setting up libgoogle-glog-dev (0.4.0-1build1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libhdf5-100 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  libhdf5-103\n",
            "\n",
            "E: Package 'libhdf5-100' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'libhdf5-dev' instead of 'libhdf5-serial-dev'\n",
            "libhdf5-dev is already the newest version (1.10.4+repack-11ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libhdf5-dev is already the newest version (1.10.4+repack-11ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libhdf5-cpp-100 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  libhdf5-cpp-103\n",
            "\n",
            "E: Package 'libhdf5-cpp-100' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5.2).\n",
            "The following NEW packages will be installed:\n",
            "  libprotobuf-dev libprotobuf-lite17\n",
            "0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,288 kB of archives.\n",
            "After this operation, 11.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libprotobuf-lite17 amd64 3.6.1.3-2ubuntu5.2 [132 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libprotobuf-dev amd64 3.6.1.3-2ubuntu5.2 [1,156 kB]\n",
            "Fetched 1,288 kB in 1s (1,363 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libprotobuf-lite17:amd64.\n",
            "(Reading database ... 131958 files and directories currently installed.)\n",
            "Preparing to unpack .../libprotobuf-lite17_3.6.1.3-2ubuntu5.2_amd64.deb ...\n",
            "Unpacking libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5.2) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../libprotobuf-dev_3.6.1.3-2ubuntu5.2_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5.2) ...\n",
            "Setting up libprotobuf-lite17:amd64 (3.6.1.3-2ubuntu5.2) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.6.1.3-2ubuntu5.2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5.so\n",
            "/usr/lib/x86_64-linux-gnu/hdf5/serial/libhdf5_hl.so\n",
            "env: CPATH=\"/usr/include/hdf5/serial/\"\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  leveldb-doc\n",
            "The following NEW packages will be installed:\n",
            "  libleveldb-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 191 kB of archives.\n",
            "After this operation, 1,101 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libleveldb-dev amd64 1.22-3ubuntu2 [191 kB]\n",
            "Fetched 191 kB in 1s (310 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "(Reading database ... 132066 files and directories currently installed.)\n",
            "Preparing to unpack .../libleveldb-dev_1.22-3ubuntu2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.22-3ubuntu2) ...\n",
            "Setting up libleveldb-dev:amd64 (1.22-3ubuntu2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgflags-dev is already the newest version (2.2.2-1build1).\n",
            "libgoogle-glog-dev is already the newest version (0.4.0-1build1).\n",
            "The following additional packages will be installed:\n",
            "  lmdb-doc\n",
            "The following NEW packages will be installed:\n",
            "  liblmdb-dev lmdb-doc\n",
            "0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 335 kB of archives.\n",
            "After this operation, 2,579 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 liblmdb-dev amd64 0.9.24-1 [59.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 lmdb-doc all 0.9.24-1 [275 kB]\n",
            "Fetched 335 kB in 1s (350 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "(Reading database ... 132095 files and directories currently installed.)\n",
            "Preparing to unpack .../liblmdb-dev_0.9.24-1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.24-1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../lmdb-doc_0.9.24-1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.24-1) ...\n",
            "Setting up lmdb-doc (0.9.24-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.24-1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libsnappy-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 29.0 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libsnappy-dev amd64 1.1.8-1build1 [29.0 kB]\n",
            "Fetched 29.0 kB in 0s (89.2 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "(Reading database ... 132319 files and directories currently installed.)\n",
            "Preparing to unpack .../libsnappy-dev_1.1.8-1build1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.8-1build1) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.8-1build1) ...\n",
            "\"/usr/include/hdf5/serial/\"\n",
            "/content/caffe\n",
            "caffe.cloc\t data\t   INSTALL.md\t\t    models     tools\n",
            "cmake\t\t docker    LICENSE\t\t    python\n",
            "CMakeLists.txt\t docs\t   Makefile\t\t    README.md\n",
            "CONTRIBUTING.md  examples  Makefile.config.example  scripts\n",
            "CONTRIBUTORS.md  include   matlab\t\t    src\n",
            "Makefile:6: *** Makefile.config not found. See Makefile.config.example..  Stop.\n",
            "PROTOC src/caffe/proto/caffe.proto\n",
            "NVCC src/caffe/solvers/adadelta_solver.cu\n",
            "NVCC src/caffe/solvers/adam_solver.cu\n",
            "NVCC src/caffe/solvers/nesterov_solver.cu\n",
            "NVCC src/caffe/solvers/adagrad_solver.cu\n",
            "NVCC src/caffe/solvers/rmsprop_solver.cu\n",
            "NVCC src/caffe/solvers/sgd_solver.cu\n",
            "NVCC src/caffe/util/im2col.cu\n",
            "NVCC src/caffe/util/math_functions.cu\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            "   54 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Ksrc/caffe/util/math_functions.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/math_functions.h:54:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            "   54 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "NVCC src/caffe/layers/inner_product_layer.cu\n",
            "NVCC src/caffe/layers/deconv_layer.cu\n",
            "In file included from src/caffe/util/math_functions.cu:1:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            "   54 | #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "      |  ^~~~~~~\n",
            "In file included from src/caffe/util/math_functions.cu:1:\n",
            "/usr/local/cuda/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n",
            "   54 | #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n",
            "      |  ^~~~~~~\n",
            "NVCC src/caffe/layers/cudnn_relu_layer.cu\n",
            "NVCC src/caffe/layers/tanh_layer.cu\n",
            "NVCC src/caffe/layers/swish_layer.cu\n",
            "NVCC src/caffe/layers/elu_layer.cu\n",
            "NVCC src/caffe/layers/softmax_layer.cu\n",
            "NVCC src/caffe/layers/lrn_layer.cu\n",
            "NVCC src/caffe/layers/eltwise_layer.cu\n",
            "NVCC src/caffe/layers/relu_layer.cu\n",
            "NVCC src/caffe/layers/silence_layer.cu\n",
            "NVCC src/caffe/layers/filter_layer.cu\n",
            "NVCC src/caffe/layers/prelu_layer.cu\n",
            "NVCC src/caffe/layers/batch_norm_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_output_layer.cu\n",
            "NVCC src/caffe/layers/reduction_layer.cu\n",
            "NVCC src/caffe/layers/base_data_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lcn_layer.cu\n",
            "NVCC src/caffe/layers/scale_layer.cu\n",
            "NVCC src/caffe/layers/euclidean_loss_layer.cu\n",
            "NVCC src/caffe/layers/embed_layer.cu\n",
            "NVCC src/caffe/layers/contrastive_loss_layer.cu\n",
            "NVCC src/caffe/layers/absval_layer.cu\n",
            "NVCC src/caffe/layers/bnll_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_tanh_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_softmax_layer.cu\n",
            "NVCC src/caffe/layers/threshold_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_pooling_layer.cu\n",
            "NVCC src/caffe/layers/softmax_loss_layer.cu\n",
            "NVCC src/caffe/layers/conv_layer.cu\n",
            "NVCC src/caffe/layers/mvn_layer.cu\n",
            "NVCC src/caffe/layers/batch_reindex_layer.cu\n",
            "NVCC src/caffe/layers/bias_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_conv_layer.cu\n",
            "NVCC src/caffe/layers/dropout_layer.cu\n",
            "NVCC src/caffe/layers/accuracy_layer.cu\n",
            "NVCC src/caffe/layers/crop_layer.cu\n",
            "NVCC src/caffe/layers/lstm_unit_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu\n",
            "NVCC src/caffe/layers/clip_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_deconv_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_sigmoid_layer.cu\n",
            "NVCC src/caffe/layers/concat_layer.cu\n",
            "NVCC src/caffe/layers/split_layer.cu\n",
            "NVCC src/caffe/layers/hdf5_data_layer.cu\n",
            "NVCC src/caffe/layers/exp_layer.cu\n",
            "NVCC src/caffe/layers/recurrent_layer.cu\n",
            "NVCC src/caffe/layers/im2col_layer.cu\n",
            "NVCC src/caffe/layers/pooling_layer.cu\n",
            "NVCC src/caffe/layers/slice_layer.cu\n",
            "NVCC src/caffe/layers/power_layer.cu\n",
            "NVCC src/caffe/layers/tile_layer.cu\n",
            "NVCC src/caffe/layers/cudnn_lrn_layer.cu\n",
            "NVCC src/caffe/layers/log_layer.cu\n",
            "NVCC src/caffe/layers/sigmoid_layer.cu\n",
            "CXX tools/upgrade_solver_proto_text.cpp\n",
            "CXX tools/extract_features.cpp\n",
            "CXX tools/upgrade_net_proto_binary.cpp\n",
            "CXX tools/caffe.cpp\n",
            "CXX tools/compute_image_mean.cpp\n",
            "CXX tools/upgrade_net_proto_text.cpp\n",
            "CXX tools/convert_imageset.cpp\n",
            "CXX examples/mnist/convert_mnist_data.cpp\n",
            "CXX examples/cifar10/convert_cifar_data.cpp\n",
            "CXX examples/siamese/convert_mnist_siamese_data.cpp\n",
            "CXX examples/cpp_classification/classification.cpp\n",
            "CXX .build_release/src/caffe/proto/caffe.pb.cc\n",
            "CXX src/caffe/solvers/sgd_solver.cpp\n",
            "examples/cpp_classification/classification.cpp:3:10: fatal error: opencv2/core/core.hpp: No such file or directory\n",
            "    3 | #include <opencv2/core/core.hpp>\n",
            "      |          ^~~~~~~~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "make: *** [Makefile:592: .build_release/examples/cpp_classification/classification.o] Error 1\n",
            "make: *** Waiting for unfinished jobs....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5wn-50gny8g",
        "outputId": "71c928e2-fdae-46a3-bdf0-a93fcb7d83f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/CVproject/Data'\n",
        "data_dir = '/content/drive/MyDrive/CVproject/Data'\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'"
      ],
      "metadata": {
        "id": "FjmmjpjAtaSw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgQcC_9yi9U-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = []\n",
        "        image_path = path + \n",
        "        with open('./training/fill50k/prompt.json', 'rt') as f:\n",
        "            for line in f:\n",
        "                self.data.append(json.loads(line))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        source_filename = item['source']\n",
        "        target_filename = item['target']\n",
        "        prompt = item['prompt']\n",
        "\n",
        "        source = cv2.imread('./training/fill50k/' + source_filename)\n",
        "        target = cv2.imread('./training/fill50k/' + target_filename)\n",
        "\n",
        "        # Do not forget that OpenCV read images in BGR order.\n",
        "        source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n",
        "        target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Normalize source images to [0, 1].\n",
        "        source = source.astype(np.float32) / 255.0\n",
        "\n",
        "        # Normalize target images to [-1, 1].\n",
        "        target = (target.astype(np.float32) / 127.5) - 1.0\n",
        "\n",
        "        return dict(jpg=target, txt=prompt, hint=source)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decipher text file**\n"
      ],
      "metadata": {
        "id": "JBDll4yVwfpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!make pycaffe"
      ],
      "metadata": {
        "id": "SuVUF3K8ww2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8022291f-f2a1-4b45-95a6-1324587dc745"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CXX src/caffe/solvers/rmsprop_solver.cpp\n",
            "CXX src/caffe/solvers/adagrad_solver.cpp\n",
            "CXX src/caffe/solvers/nesterov_solver.cpp\n",
            "CXX src/caffe/solvers/adam_solver.cpp\n",
            "CXX src/caffe/solvers/adadelta_solver.cpp\n",
            "CXX src/caffe/layer.cpp\n",
            "CXX src/caffe/util/math_functions.cpp\n",
            "CXX src/caffe/util/im2col.cpp\n",
            "CXX src/caffe/util/blocking_queue.cpp\n",
            "CXX src/caffe/util/db.cpp\n",
            "CXX src/caffe/util/db_lmdb.cpp\n",
            "CXX src/caffe/util/io.cpp\n",
            "src/caffe/util/io.cpp:6:10: fatal error: opencv2/core/core.hpp: No such file or directory\n",
            "    6 | #include <opencv2/core/core.hpp>\n",
            "      |          ^~~~~~~~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "make: *** [Makefile:592: .build_release/src/caffe/util/io.o] Error 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Run the dataset through HED**"
      ],
      "metadata": {
        "id": "lH-IHNnBkUhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HED batch processing script; modified from https://github.com/s9xie/hed/blob/master/examples/hed/HED-tutorial.ipynb\n",
        "# Step 1: download the hed repo: https://github.com/s9xie/hed\n",
        "# Step 2: download the models and protoxt, and put them under {caffe_root}/examples/hed/\n",
        "# Step 3: put this script under {caffe_root}/examples/hed/\n",
        "# Step 4: run the following script:\n",
        "#       python batch_hed.py --images_dir=/data/to/path/photos/ --hed_mat_dir=/data/to/path/hed_mat_files/\n",
        "# The code sometimes crashes after computation is done. Error looks like \"Check failed: ... driver shutting down\". You can just kill the job.\n",
        "# For large images, it will produce gpu memory issue. Therefore, you better resize the images before running this script.\n",
        "# Step 5: run the MATLAB post-processing script \"PostprocessHED.m\"\n",
        "\n",
        "import scipy.io as sio\n",
        "import caffe\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='batch proccesing: photos->edges')\n",
        "    parser.add_argument('--caffe_root', dest='caffe_root', help='caffe root', default='../../', type=str)\n",
        "    parser.add_argument('--caffemodel', dest='caffemodel', help='caffemodel', default='./hed_pretrained_bsds.caffemodel', type=str)\n",
        "    parser.add_argument('--prototxt', dest='prototxt', help='caffe prototxt file', default='./deploy.prototxt', type=str)\n",
        "    parser.add_argument('--images_dir', dest='images_dir', help='directory to store input photos', default=path+'/data', type=str)\n",
        "    parser.add_argument('--hed_mat_dir', dest='hed_mat_dir', help='directory to store output hed edges in mat file', type=str)\n",
        "    parser.add_argument('--border', dest='border', help='padding border', type=int, default=128)\n",
        "    parser.add_argument('--gpu_id', dest='gpu_id', help='gpu id', type=int, default=1)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "for arg in vars(args):\n",
        "    print('[%s] =' % arg, getattr(args, arg))\n",
        "# Make sure that caffe is on the python path:\n",
        "caffe_root = args.caffe_root   # this file is expected to be in {caffe_root}/examples/hed/\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "\n",
        "\n",
        "if not os.path.exists(args.hed_mat_dir):\n",
        "    print('create output directory %s' % args.hed_mat_dir)\n",
        "    os.makedirs(args.hed_mat_dir)\n",
        "\n",
        "imgList = os.listdir(args.images_dir)\n",
        "nImgs = len(imgList)\n",
        "print('#images = %d' % nImgs)\n",
        "\n",
        "caffe.set_mode_gpu()\n",
        "caffe.set_device(args.gpu_id)\n",
        "# load net\n",
        "net = caffe.Net(args.prototxt, args.caffemodel, caffe.TEST)\n",
        "# pad border\n",
        "border = args.border\n",
        "\n",
        "for i in range(nImgs):\n",
        "    if i % 500 == 0:\n",
        "        print('processing image %d/%d' % (i, nImgs))\n",
        "    im = Image.open(os.path.join(args.images_dir, imgList[i]))\n",
        "\n",
        "    in_ = np.array(im, dtype=np.float32)\n",
        "    in_ = np.pad(in_, ((border, border), (border, border), (0, 0)), 'reflect')\n",
        "\n",
        "    in_ = in_[:, :, 0:3]\n",
        "    in_ = in_[:, :, ::-1]\n",
        "    in_ -= np.array((104.00698793, 116.66876762, 122.67891434))\n",
        "    in_ = in_.transpose((2, 0, 1))\n",
        "    # remove the following two lines if testing with cpu\n",
        "\n",
        "    # shape for input (data blob is N x C x H x W), set data\n",
        "    net.blobs['data'].reshape(1, *in_.shape)\n",
        "    net.blobs['data'].data[...] = in_\n",
        "    # run net and take argmax for prediction\n",
        "    net.forward()\n",
        "    fuse = net.blobs['sigmoid-fuse'].data[0][0, :, :]\n",
        "    # get rid of the border\n",
        "    fuse = fuse[(border+35):(-border+35), (border+35):(-border+35)]\n",
        "    # save hed file to the disk\n",
        "    name, ext = os.path.splitext(imgList[i])\n",
        "    sio.savemat(os.path.join(args.hed_mat_dir, name + '.mat'), {'edge_predict': fuse})"
      ],
      "metadata": {
        "id": "4yBxxOb-t9CY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "3b6343c7-3c94-4448-a979-c5c7f215a4e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-856fa3db849a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'caffe._caffe'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}